{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57195cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "from keras_facenet import FaceNet\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a84ba6ed-ec37-42c1-8891-7c1f4f575df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "class FACELOADING:\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.target_size = (100, 100)\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        self.detector = MTCNN()\n",
    "        self.embedder = FaceNet()\n",
    "        self.encoder = LabelEncoder()\n",
    "        self.model = SVC(kernel='linear', probability=True)\n",
    "\n",
    "    def extract_face(self, filename):\n",
    "        img = cv.imread(filename)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        x, y, w, h = self.detector.detect_faces(img)[0]['box']\n",
    "        x, y = abs(x), abs(y)\n",
    "        face = img[y:y+h, x:x+w]\n",
    "        face_arr = cv.resize(face, self.target_size)\n",
    "        return face_arr\n",
    "\n",
    "    def load_faces(self, dir):\n",
    "        FACES = []\n",
    "        for im_name in os.listdir(dir):\n",
    "            try:\n",
    "                path = os.path.join(dir, im_name)\n",
    "                single_face = self.extract_face(path)\n",
    "                FACES.append(single_face)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        return FACES\n",
    "\n",
    "    def load_classes(self):\n",
    "        for sub_dir in os.listdir(self.directory):\n",
    "            path = os.path.join(self.directory, sub_dir)\n",
    "            FACES = self.load_faces(path)\n",
    "            labels = [sub_dir for _ in range(len(FACES))]\n",
    "            print(f\"Loaded successfully: {len(labels)}\")\n",
    "            self.X.extend(FACES)\n",
    "            self.Y.extend(labels)\n",
    "\n",
    "        self.encoder.fit(self.Y)\n",
    "        self.Y_encoded = self.encoder.transform(self.Y)\n",
    "        self.X_embedded = self.embedder.embeddings(np.asarray(self.X))\n",
    "        self.model.fit(self.X_embedded, self.Y_encoded)\n",
    "\n",
    "    def save_model(self, model_file, encoder_file):\n",
    "        with open(model_file, 'wb') as file:\n",
    "            pickle.dump(self.model, file)\n",
    "        with open(encoder_file, 'wb') as file:\n",
    "            pickle.dump(self.encoder, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f307272b-a53a-4ee6-b1a4-c94279702cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded successfully: 0\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Loaded successfully: 2\n",
      "Loaded successfully: 0\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Loaded successfully: 2\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    }
   ],
   "source": [
    "# Define the directory containing the face dataset\n",
    "directory = \"C:/Users/Praveen nallasivam/Desktop/codes/New/face_recognization/dataset\"\n",
    "model_file = \"trained_model.pkl\"\n",
    "encoder_file = \"label_encoder.pkl\"\n",
    "\n",
    "faceloading = FACELOADING(directory)\n",
    "faceloading.load_classes()\n",
    "faceloading.save_model(model_file, encoder_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be534930",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from mtcnn import MTCNN\n",
    "from keras_facenet import FaceNet\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57dbd05-a91a-468f-9d0d-1727f0bcc294",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FACELOADING:\n",
    "    def __init__(self, model_file, encoder_file):\n",
    "        self.target_size = (100, 100)\n",
    "        self.detector = MTCNN()\n",
    "        self.embedder = FaceNet()\n",
    "        self.model = pickle.load(open(model_file, 'rb'))\n",
    "        self.encoder = pickle.load(open(encoder_file, 'rb'))\n",
    "\n",
    "    def recognize_face(self):\n",
    "        cap = cv.VideoCapture(0)\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                frame = cv.flip(frame, 1)  # flip the frame horizontally for a mirror effect\n",
    "                frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "                results = self.detector.detect_faces(frame)\n",
    "                if results:\n",
    "                    for result in results:\n",
    "                        x, y, w, h = result['box']\n",
    "                        x, y = abs(x), abs(y)\n",
    "                        face = frame[y:y+h, x:x+w]\n",
    "                        face_arr = cv.resize(face, self.target_size)\n",
    "                        face_embedded = self.embedder.embeddings(np.asarray([face_arr]))\n",
    "                        pred_encoded = self.model.predict(face_embedded)\n",
    "                        pred_proba = self.model.predict_proba(face_embedded)\n",
    "                        pred_proba = np.max(pred_proba) * 100\n",
    "                        if pred_encoded in self.encoder.transform(self.encoder.classes_):\n",
    "                            pred_name = self.encoder.inverse_transform(pred_encoded)\n",
    "                            cv.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                            cv.putText(frame, f\"{pred_name[0]} ({pred_proba:.2f}%)\", (x, y-10), cv.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                        else:\n",
    "                            cv.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "                            cv.putText(frame, \"Unrecognized face: Entry denied\", (x, y-10), cv.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                cv.imshow('frame', frame)\n",
    "                if cv.waitKey(1) == ord('q'):\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "        cap.release()\n",
    "        cv.destroyAllWindows()\n",
    "\n",
    "# Define the paths to the pre-trained model and label encoder files\n",
    "model_file = \"trained_model.pkl\"\n",
    "encoder_file = \"label_encoder.pkl\"\n",
    "\n",
    "faceloading = FACELOADING(model_file, encoder_file)\n",
    "faceloading.recognize_face()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d55b986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Define the directory where the dataset will be saved\n",
    "dataset_dir =   \"C:/Users/Praveen nallasivam/Desktop/codes/New/face_recognization/dataset\"\n",
    "\n",
    "# Create the dataset directory if it does not exist\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.makedirs(dataset_dir)\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "# Define the face detector\n",
    "face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Initialize a counter for the number of images captured\n",
    "img_counter = 0\n",
    "\n",
    "# Ask for the person's name\n",
    "name = input(\"Enter the person's name: \")\n",
    "\n",
    "# Create a folder in the dataset directory with the person's name\n",
    "person_dir = os.path.join(dataset_dir, name)\n",
    "if not os.path.exists(person_dir):\n",
    "    os.makedirs(person_dir)\n",
    "\n",
    "# Capture images until 10 images are captured\n",
    "while img_counter < 10:\n",
    "    # Read a frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_detector.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "    \n",
    "    if len(faces) == 1:\n",
    "        (x, y, w, h) = faces[0]\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Crop the face region from the frame\n",
    "        face = gray[y:y+h, x:x+w]\n",
    "        \n",
    "        # Perform intensity normalization on the face\n",
    "        face_normalized = cv2.equalizeHist(face)\n",
    "\n",
    "        # Resize the face image to a fixed size (e.g., 100x100)\n",
    "        resized_face = cv2.resize(face_normalized, (100, 100))\n",
    "\n",
    "        # Flatten the face image into a 1D array\n",
    "        flattened_face = resized_face.flatten()\n",
    "\n",
    "        # Save the flattened face image\n",
    "        img_name = f\"{person_dir}/{name}_{img_counter}.jpg\"\n",
    "        cv2.imwrite(img_name, resized_face)\n",
    "\n",
    "        img_counter += 1\n",
    "    elif len(faces) > 1:\n",
    "        cv2.putText(frame, \"Multiple faces detected. Please ensure only 1 is present.\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    else:\n",
    "        cv2.putText(frame, \"No faces detected. Please position your face correctly.\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('Capture Face', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f254d1f5-c409-4282-9b33-7f7ee3e381a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
